{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'modules.tf.load_img' from '/media/taesookim/0C8ECA3C8ECA1E58/Users/terry/source/repos/tensorflow2_notebooks/modules/tf/load_img.py'>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import modules.tf.load_img as load_img\n",
    "import importlib\n",
    "importlib.reload(load_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import mixed_precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_XLA_FLAGS']=\"--tf_xla_enable_xla_devices\"\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'),\n PhysicalDevice(name='/physical_device:XLA_GPU:2', device_type='XLA_GPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def seq(lyrs):\n",
    "  return [tf.keras.models.Sequential(lyr) for lyr in lyrs]\n",
    "\n",
    "#Note: This design can be improved (i.e Conv->BN->Activation).\n",
    "def model_autoencoder():\n",
    "  inp = tf.keras.layers.Input([16, 16, 1])\n",
    "\n",
    "  layers = seq([tf.keras.layers.Conv2D(16, kernel_size=(3,3), strides=2, padding=\"same\", activation=tf.nn.leaky_relu),#16\n",
    "                                tf.keras.layers.Conv2D(32, kernel_size=(3,3), strides=2, padding=\"same\", activation=tf.nn.leaky_relu),#8\n",
    "                                tf.keras.layers.Conv2D(64, kernel_size=(3,3), strides=2, padding=\"same\", activation=tf.nn.leaky_relu),#4\n",
    "                                tf.keras.layers.Conv2D(128, kernel_size=(3,3), strides=2, padding=\"same\", activation=tf.nn.leaky_relu),#2\n",
    "                                tf.keras.layers.Conv2D(256, kernel_size=(3,3), strides=2, padding=\"same\", activation=tf.nn.leaky_relu),#1\n",
    "                                tf.keras.layers.Conv2D(512, kernel_size=(3,3), strides=2, padding=\"same\", activation=tf.nn.leaky_relu),#1\n",
    "                                tf.keras.layers.Conv2D(256, kernel_size=(3,3), strides=2, padding=\"same\", activation=tf.nn.leaky_relu),#1\n",
    "                                tf.keras.layers.Conv2DTranspose(128, kernel_size=(3,3), strides=2, padding=\"same\", activation=tf.nn.leaky_relu),#2\n",
    "                                tf.keras.layers.Conv2DTranspose(64, kernel_size=(3,3), strides=2, padding=\"same\", activation=tf.nn.leaky_relu),#4\n",
    "                                tf.keras.layers.Conv2DTranspose(32, kernel_size=(3,3), strides=2, padding=\"same\", activation=tf.nn.leaky_relu),#8\n",
    "                                tf.keras.layers.Conv2DTranspose(1, kernel_size=(3,3), strides=2, padding=\"same\", activation=tf.nn.tanh, dtype=tf.float32 ) #16\n",
    "          ])\n",
    "  prev = inp\n",
    "  skips = []\n",
    "  for layer in layers[:6]:\n",
    "    prev = layer(prev)\n",
    "    skips.append(prev)\n",
    "\n",
    "  skips = skips[:5]\n",
    "  for skip, layer in zip(reversed(skips), layers[6:]):\n",
    "    prev = tf.keras.layers.concatenate([skip, prev])\n",
    "    prev = layer(prev)\n",
    "\n",
    "  return tf.keras.Model(inputs=inp, outputs=prev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "GLOBAL_BATCH_SIZE = 32 * strategy.num_replicas_in_sync"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_imgs = load_img.load_mnist(GLOBAL_BATCH_SIZE, tiny=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_imgs = strategy.experimental_distribute_dataset(train_imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# for datamap in train_imgs:\n",
    "#     img, img_2, img_fn = datamap\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = model_autoencoder()\n",
    "    loss_object = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    def compute_loss(real, pred):\n",
    "        per_example_loss = loss_object(real, pred)\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    optimizer = mixed_precision.LossScaleOptimizer(optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs):\n",
    "    img, img_fn = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(img * 0.5, training=True)\n",
    "        loss = compute_loss(img, pred)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss)\n",
    "    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def distributed_train_step(inputs):\n",
    "    per_replica_losses = strategy.run(train_step, args=(inputs, ))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                           axis=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 22 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "83.8918457\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "86.2702332\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "93.0373383\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "85.7491913\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "89.3180618\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "86.2214203\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "88.9926605\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "86.3106918\n",
      "85.8832321\n",
      "80.4536362\n",
      "84.4116898\n",
      "79.7794266\n",
      "77.6809845\n",
      "77.8407211\n",
      "77.1062775\n",
      "77.068573\n",
      "76.1052551\n",
      "73.9507446\n",
      "73.2564392\n",
      "70.0528641\n",
      "75.4339752\n",
      "72.2067108\n",
      "70.3834152\n",
      "69.04039\n",
      "62.9818649\n",
      "68.3202286\n",
      "62.3142662\n",
      "63.7442245\n",
      "63.9083405\n",
      "59.6419792\n",
      "59.8802834\n",
      "59.7349358\n",
      "52.8248253\n",
      "55.0205231\n",
      "53.5659866\n",
      "51.608017\n",
      "50.7513199\n",
      "48.8869705\n",
      "45.4837646\n",
      "46.3830566\n",
      "46.9792023\n",
      "45.7221146\n",
      "45.6996384\n",
      "43.720932\n",
      "41.6651878\n",
      "42.3633804\n",
      "41.4119568\n",
      "39.9131088\n",
      "39.0870514\n",
      "40.0686302\n",
      "40.6028519\n",
      "38.1585274\n",
      "36.6087532\n",
      "37.3622627\n",
      "34.2149849\n",
      "35.2332954\n",
      "34.5256386\n",
      "35.723465\n",
      "33.2068787\n",
      "33.9420624\n",
      "32.6435471\n",
      "33.048748\n",
      "31.0343876\n",
      "31.182663\n",
      "32.1038589\n",
      "29.7041645\n",
      "31.2278786\n",
      "29.6578903\n",
      "29.9000893\n",
      "30.5196381\n",
      "29.4535179\n",
      "28.4178581\n",
      "27.9937592\n",
      "28.5591755\n",
      "27.1342201\n",
      "26.0700455\n",
      "26.006279\n",
      "27.1598015\n",
      "27.1667137\n",
      "27.3106804\n",
      "26.7769775\n",
      "25.6743393\n",
      "24.8481884\n",
      "25.1196575\n",
      "25.5877209\n",
      "25.3187428\n",
      "25.4923973\n",
      "23.540472\n",
      "23.2205925\n",
      "24.9186153\n",
      "23.3202744\n",
      "23.7151\n",
      "22.929203\n",
      "23.5519\n",
      "22.1061916\n",
      "22.174078\n",
      "23.3489532\n",
      "22.0083427\n",
      "21.7810535\n",
      "22.1858482\n",
      "21.5485306\n",
      "20.9273529\n",
      "20.7777729\n",
      "20.8366241\n",
      "20.3055077\n",
      "20.4591904\n",
      "20.4692726\n",
      "20.1250801\n",
      "21.1438351\n",
      "20.053257\n",
      "19.2548218\n",
      "18.8687115\n",
      "19.0209446\n",
      "18.8906708\n",
      "19.1585903\n",
      "19.6775188\n",
      "18.969717\n",
      "18.802784\n",
      "19.6342\n",
      "18.4163971\n",
      "18.5427284\n",
      "19.8968277\n",
      "18.1144943\n",
      "17.9843063\n",
      "18.3027744\n",
      "18.1367111\n",
      "19.084877\n",
      "17.1997185\n",
      "16.8010216\n",
      "18.1968307\n",
      "17.8103085\n",
      "17.5321884\n",
      "17.6305428\n",
      "16.3359604\n",
      "17.440218\n",
      "16.5394382\n",
      "17.3466492\n",
      "16.9694462\n",
      "17.235466\n",
      "17.0761356\n",
      "16.2446289\n",
      "16.9828472\n",
      "16.3372517\n",
      "16.2331085\n",
      "16.2507286\n",
      "16.1646156\n",
      "15.7926807\n",
      "15.3914423\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-7378cda81548>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtrain_imgs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdistributed_train_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Fashionv1/lib/python3.8/site-packages/tensorflow/python/distribute/input_lib.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    630\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    631\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 632\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_next\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    633\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOutOfRangeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    634\u001B[0m       \u001B[0;32mraise\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Fashionv1/lib/python3.8/site-packages/tensorflow/python/distribute/input_lib.py\u001B[0m in \u001B[0;36mget_next\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    674\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    675\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 676\u001B[0;31m     global_has_value, replicas = _get_next_as_optional(\n\u001B[0m\u001B[1;32m    677\u001B[0m         self, self._strategy, return_per_replica=False)\n\u001B[1;32m    678\u001B[0m     \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Fashionv1/lib/python3.8/site-packages/tensorflow/python/distribute/input_lib.py\u001B[0m in \u001B[0;36m_get_next_as_optional\u001B[0;34m(iterator, strategy, return_per_replica)\u001B[0m\n\u001B[1;32m    547\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mworker\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    548\u001B[0m       worker_has_value, next_element = (\n\u001B[0;32m--> 549\u001B[0;31m           iterator._iterators[i].get_next_as_list())  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m    550\u001B[0m       \u001B[0;31m# Collective all-reduce requires explicit devices for inputs.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    551\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/cpu:0\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Fashionv1/lib/python3.8/site-packages/tensorflow/python/distribute/input_lib.py\u001B[0m in \u001B[0;36mget_next_as_list\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1638\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_worker\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1639\u001B[0m       data_list = self._format_data_list_with_options(\n\u001B[0;32m-> 1640\u001B[0;31m           self._iterator.get_next_as_optional())\n\u001B[0m\u001B[1;32m   1641\u001B[0m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1642\u001B[0m       \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Fashionv1/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py\u001B[0m in \u001B[0;36mget_next_as_optional\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    602\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_devices\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    603\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 604\u001B[0;31m         \u001B[0mresult\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_device_iterators\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_next_as_optional\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    605\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    606\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Fashionv1/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001B[0m in \u001B[0;36mget_next_as_optional\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    805\u001B[0m       \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    806\u001B[0m       return optional_ops._OptionalImpl(\n\u001B[0;32m--> 807\u001B[0;31m           gen_dataset_ops.iterator_get_next_as_optional(\n\u001B[0m\u001B[1;32m    808\u001B[0m               \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iterator_resource\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    809\u001B[0m               \u001B[0moutput_types\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstructure\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_flat_tensor_types\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0melement_spec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Fashionv1/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001B[0m in \u001B[0;36miterator_get_next_as_optional\u001B[0;34m(iterator, output_types, output_shapes, name)\u001B[0m\n\u001B[1;32m   2653\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2654\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2655\u001B[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0m\u001B[1;32m   2656\u001B[0m         \u001B[0m_ctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"IteratorGetNextAsOptional\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"output_types\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2657\u001B[0m         output_types, \"output_shapes\", output_shapes)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    for data in train_imgs:\n",
    "        loss = distributed_train_step(data)\n",
    "        tf.print(loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}